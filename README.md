# Reading List of LLM-based Data Science Agents.

1. [How Do Analysts Understand and Verify AI-Assisted Data Analyses?](https://arxiv.org/abs/2309.10947)
2. [AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation](https://arxiv.org/abs/2309.15656)
3. [Multimodal-Toolkit: A Package for Learning on Tabular and Text Data with Transformers](https://arxiv.org/abs/2305.14607)
4. [HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face](https://arxiv.org/abs/2303.17580)
5. [AnaMeta](https://arxiv.org/abs/2310.06891)
6. [Large Language Models for Automated Data Science: Introducing CAAFE for Context-Aware Automated Feature Engineering](https://arxiv.org/abs/2309.03419)
7. [Investigating Interaction Modes and User Agency in Human-LLM Collaboration for Domain-Specific Data Analysis](https://arxiv.org/abs/2311.05631)
8. [ChatGPT as your Personal Data Scientist](https://arxiv.org/abs/2306.08668)
9. [LAMBDA: A Large Model-Based Data Agent](https://arxiv.org/abs/2309.12737)
10. [Text2Analysis](https://arxiv.org/abs/2304.14007)
11. [JarviX: A LLM No-code Platform for Tabular Data Analysis and Optimization](https://arxiv.org/abs/2310.14536)
12. [AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML](https://arxiv.org/abs/2310.07632)
13. [Large Language Models for Tabular Data: Progresses and Future Directions](https://arxiv.org/abs/2310.13432)
14. [Is GPT-4 a Good Data Analyst?](https://arxiv.org/abs/2310.10965)
15. [Language Models Enable Simple Systems for Generating Structured Views of Heterogeneous Data Lakes](https://arxiv.org/abs/2310.12123)
16. [ChatDev: Communicative Agents for Software Development](https://arxiv.org/abs/2309.09792)
17. [LLM-Enhanced Data Management](https://arxiv.org/abs/2311.03302)
18. [SELA: Tree-Search Enhanced LLM Agents for Automated Machine Learning](https://arxiv.org/abs/2311.05008)
19. [AutoM3L: An Automated Multimodal Machine Learning Framework with Large Language Models](https://arxiv.org/abs/2310.08549)
20. [AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions](https://arxiv.org/abs/2311.03908)
21. [An Autonomous Large Language Model Agent for Chemical Literature Data Mining](https://arxiv.org/abs/2310.05032)
22. [DS-Agent: Automated Data Science by Empowering Large Language Models with Case-Based Reasoning](https://arxiv.org/abs/2309.14560)
23. [Data Interpreter](https://arxiv.org/abs/2310.14656)
24. [Training and Evaluating a Jupyter Notebook Data Science Assistant](https://arxiv.org/abs/2310.08192)
25. [How Do Data Analysts Respond to AI Assistance? A Wizard-of-Oz Study](https://arxiv.org/abs/2310.11434)
26. [SEED: Domain-Specific Data Curation With Large Language Models](https://arxiv.org/abs/2310.13575)
27. [MatPlotAgent: Method and Evaluation for LLM-Based Agentic Scientific Data Visualization](https://arxiv.org/abs/2310.15028)
28. [TaskWeaver: A Code-First Agent Framework](https://arxiv.org/abs/2311.02556)
29. [OpenAgents: An Open Platform for Language Agents in the Wild](https://arxiv.org/abs/2310.14348)
30. [Agent K v1.0](https://arxiv.org/abs/2310.14572)
31. [Data Formulator 2: Iteratively Creating Rich Visualizations with AI](https://arxiv.org/abs/2310.15718)
32. [XInsight](https://arxiv.org/abs/2311.04413)
33. [MLCopilot: Unleashing the Power of Large Language Models in Solving Machine Learning Tasks](https://arxiv.org/abs/2310.13149)
34. [Execution-based Evaluation for Data Science Code Generation Models](https://arxiv.org/abs/2310.09188)
35. [Data-Copilot: Bridging Billions of Data and Humans with Autonomous Workflow](https://arxiv.org/abs/2311.03002)
36. [WaitGPT: Monitoring and Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization](https://arxiv.org/abs/2310.14192)
37. [InsightPilot](https://arxiv.org/abs/2310.14001)
38. [Executable Code Actions Elicit Better LLM Agents](https://arxiv.org/abs/2310.09234)
39. [Data Formulator: AI-powered Concept-driven Visualization Authoring](https://arxiv.org/abs/2310.13768)
40. [DA-Code: Agent Data Science Code Generation Benchmark for Large Language Models](https://arxiv.org/abs/2310.12101)
41. [BLADE: Benchmarking Language Model Agents for Data-Driven Science](https://arxiv.org/abs/2311.01584)
42. [InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks](https://arxiv.org/abs/2310.13972)
43. [Data Analysis in the Era of Generative AI](https://arxiv.org/abs/2311.04378)
44. [Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study](https://arxiv.org/abs/2310.11254)
45. [Large Language Models as Data Preprocessors](https://arxiv.org/abs/2310.13957)
46. [Benchmarking Data Science Agents](https://arxiv.org/abs/2310.13424)
47. [DS-1000: A Natural and Reliable Benchmark for Data Science Code Generation](https://arxiv.org/abs/2310.11465)
48. [Spider2-V: How Far Are Multimodal Agents From Automating Data Science and Engineering Workflows?](https://arxiv.org/abs/2311.04079)

This should help you access the relevant papers easily! If you need any specific details or further information about these papers, feel free to ask.
